{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Workshop on (hand-crafted) feature representation\n",
        "\n",
        "Course: Vision Systems\n",
        "\n",
        "## Objective\n",
        "In this workshop, we will develop a two-class fingerprint spoof classifier that uses Local Binary Patterns (LBP) and Histogram of Oriented Gradients (HOG) features with Support Vector Machines (SVM) to distinguish live fingerprints images from spoof samples.\n",
        "\n",
        "Reference: https://github.com/shashank140195/LBP-HOG-SVM-Feature-Extraction\n"
      ],
      "metadata": {
        "id": "Myvx2W6OXJJE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7D_4G4dIXIhZ"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import math\n",
        "import pandas as pd\n",
        "from skimage.feature import local_binary_pattern\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount your drive\n",
        "# Run this cell, then youâ€™ll see a link, click on that link, allow access\n",
        "# Copy the code that pops up, Paste it in the box, Hit enter\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Change working directory to be current folder, please keep ''/content/gdrive/My Drive/XXX' in the path\n",
        "# and change XXX to be your own folder. The pathname is case sensitive.\n",
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/recsys/iss/VSE/day1')\n",
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3WjUyk_XdJr",
        "outputId": "664bc692-3f54-4270-953a-cbf04ac24e2d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JQy4iXX6XIhc"
      },
      "outputs": [],
      "source": [
        "# method to create data set\n",
        "def create_dataset(live_path, spoof_path, descriptor):\n",
        "\n",
        "    # list to store extracted features of an image\n",
        "    features = []\n",
        "\n",
        "    # list to store class label, 1 for live, 0 for spoof\n",
        "    labels = []\n",
        "\n",
        "    radius = 3\n",
        "\n",
        "    # number of neighbors to consider for LBP\n",
        "    n_points = 8 * radius\n",
        "\n",
        "    # sampling type for LBP\n",
        "    METHOD = 'uniform'\n",
        "\n",
        "    path_array = [live_path, spoof_path]\n",
        "\n",
        "    for path in path_array:\n",
        "\n",
        "        # storing all images in a folder in a list 'files'\n",
        "        files = os.listdir(path)\n",
        "\n",
        "        # loop through the images in the folder\n",
        "        #for img in files:\n",
        "        for img_index, img in enumerate(files):\n",
        "            if (img_index % 50) ==0:\n",
        "                print(\"%s: Process image %d/%d\" % (path, img_index, len(files)))\n",
        "\n",
        "            # reading the image in grayscale using cv2\n",
        "            img = cv2.imread(path + img, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "            # resizing the image so all images are of same size\n",
        "            IMG_HEIGHT = 128\n",
        "            IMG_WIDTH = 64\n",
        "            resized_img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
        "\n",
        "            # Extracting features of an image using LBP\n",
        "            if descriptor == 'LBP':\n",
        "                lbp = local_binary_pattern(resized_img, n_points, radius, METHOD)\n",
        "\n",
        "                 # Converting into 1-D array\n",
        "                fd = lbp.flatten()\n",
        "\n",
        "            # Extracting features of an image using HOG\n",
        "            else:\n",
        "                hog = cv2.HOGDescriptor(_winSize=(IMG_WIDTH, IMG_HEIGHT), _blockSize=(16, 16), _blockStride=(8,8), _cellSize=(8,8), _nbins=9)\n",
        "                fd = hog.compute(resized_img)\n",
        "\n",
        "            # label 1 for live images, 0 for spoof images\n",
        "            class_identifier = 1\n",
        "            if 'Spoof' in path:\n",
        "                class_identifier = 0\n",
        "\n",
        "             # appending exracted features to the list\n",
        "            features.append(fd)\n",
        "\n",
        "            #adding corresponding class label to the list\n",
        "            labels.append(class_identifier)\n",
        "\n",
        "    return features, labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "MMrj5T-HXIhd"
      },
      "outputs": [],
      "source": [
        "# Set up folders\n",
        "training_live_path = \"data/Training_Live/\"\n",
        "training_spoof_path = \"data/Training_Spoof/\"\n",
        "testing_live_path = \"data/Testing_Live/\"\n",
        "testing_spoof_path = \"data/Testing_Spoof/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TE5cyqEkXIhd",
        "outputId": "d8e2d06a-db5b-4ac7-d9b4-8c89204031b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/Training_Live/: Process image 0/200\n",
            "data/Training_Live/: Process image 50/200\n",
            "data/Training_Live/: Process image 100/200\n",
            "data/Training_Live/: Process image 150/200\n",
            "data/Training_Spoof/: Process image 0/200\n",
            "data/Training_Spoof/: Process image 50/200\n",
            "data/Training_Spoof/: Process image 100/200\n",
            "data/Training_Spoof/: Process image 150/200\n",
            "data/Testing_Live/: Process image 0/200\n",
            "data/Testing_Live/: Process image 50/200\n",
            "data/Testing_Live/: Process image 100/200\n",
            "data/Testing_Live/: Process image 150/200\n",
            "data/Testing_Spoof/: Process image 0/200\n",
            "data/Testing_Spoof/: Process image 50/200\n",
            "data/Testing_Spoof/: Process image 100/200\n",
            "data/Testing_Spoof/: Process image 150/200\n",
            "       Spoof  Live\n",
            "Spoof    198     2\n",
            "Live      51   149\n",
            "Accuracy: 0.8675\n",
            "Precision: 0.8910\n",
            "Recall: 0.8675\n"
          ]
        }
      ],
      "source": [
        "# LBP + SVM\n",
        "\n",
        "# Training and testing datasets\n",
        "lbp_x_trn,lbp_y_trn = create_dataset(training_live_path,training_spoof_path, 'LBP')\n",
        "lbp_x_tst,lbp_y_tst = create_dataset(testing_live_path,testing_spoof_path, 'LBP')\n",
        "\n",
        "# Create and fit the model\n",
        "lbp_clf = svm.SVC()\n",
        "lbp_clf.fit(lbp_x_trn,lbp_y_trn)\n",
        "\n",
        "# Predict on test data\n",
        "lbp_y_pred = lbp_clf.predict(lbp_x_tst)\n",
        "\n",
        "cf_matrix = confusion_matrix(lbp_y_tst, lbp_y_pred)\n",
        "print(pd.DataFrame(cf_matrix, index=['Spoof', 'Live'], columns=['Spoof', 'Live']))\n",
        "\n",
        "# accuracy: (tp + tn) / (p + n)\n",
        "accuracy = accuracy_score(lbp_y_tst, lbp_y_pred)\n",
        "print('Accuracy: %.4f' % accuracy)\n",
        "\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(lbp_y_tst, lbp_y_pred, average='macro')\n",
        "print('Precision: %.4f' % precision)\n",
        "\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(lbp_y_tst, lbp_y_pred, average='macro')\n",
        "print('Recall: %.4f' % recall)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foPmLOtxXIhe",
        "outputId": "897dabe8-f799-43f4-9088-d9e7819b2ed4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/Training_Live/: Process image 0/200\n",
            "data/Training_Live/: Process image 50/200\n",
            "data/Training_Live/: Process image 100/200\n",
            "data/Training_Live/: Process image 150/200\n",
            "data/Training_Spoof/: Process image 0/200\n",
            "data/Training_Spoof/: Process image 50/200\n",
            "data/Training_Spoof/: Process image 100/200\n",
            "data/Training_Spoof/: Process image 150/200\n",
            "data/Testing_Live/: Process image 0/200\n",
            "data/Testing_Live/: Process image 50/200\n",
            "data/Testing_Live/: Process image 100/200\n",
            "data/Testing_Live/: Process image 150/200\n",
            "data/Testing_Spoof/: Process image 0/200\n",
            "data/Testing_Spoof/: Process image 50/200\n",
            "data/Testing_Spoof/: Process image 100/200\n",
            "data/Testing_Spoof/: Process image 150/200\n",
            "       Spoof  Live\n",
            "Spoof    192     8\n",
            "Live      55   145\n",
            "Accuracy: 0.8425\n",
            "Precision: 0.8625\n",
            "Recall: 0.8425\n"
          ]
        }
      ],
      "source": [
        "#HoG + SVM\n",
        "\n",
        "# Training and testing datasets\n",
        "hog_x_trn,hog_y_trn = create_dataset(training_live_path,training_spoof_path, 'HOG')\n",
        "hog_x_tst,hog_y_tst = create_dataset(testing_live_path,testing_spoof_path, 'HOG')\n",
        "\n",
        "# Create and fit the model\n",
        "hog_clf = svm.SVC()\n",
        "hog_clf.fit(hog_x_trn,hog_y_trn)\n",
        "\n",
        "# Predict on test data\n",
        "hog_y_pred = hog_clf.predict(hog_x_tst)\n",
        "\n",
        "cf_matrix = confusion_matrix(hog_y_tst, hog_y_pred)\n",
        "print(pd.DataFrame(cf_matrix, index=['Spoof', 'Live'], columns=['Spoof', 'Live']))\n",
        "\n",
        "# accuracy: (tp + tn) / (p + n)\n",
        "accuracy = accuracy_score(hog_y_tst, hog_y_pred)\n",
        "print('Accuracy: %.4f' % accuracy)\n",
        "\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(hog_y_tst, hog_y_pred, average='macro')\n",
        "print('Precision: %.4f' % precision)\n",
        "\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(hog_y_tst, hog_y_pred, average='macro')\n",
        "print('Recall: %.4f' % recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sdOQ0PfXIhe"
      },
      "outputs": [],
      "source": [
        "# Provide your answers to Q1 here\n",
        "# No, there isn't a requirement to use a colour histogram. We are more concerned with the intensity and pattern of image. Therefore, even using\n",
        "# a simple grayscale histogram would be adequate.\n",
        "\n",
        "# Provide your answers to Q2 here\n",
        "# The LBP feature can account for multiple scale change features. It is resistant to resolution. The HOG can be used to identify rotation and then\n",
        "# apply transform to counteract it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Udn98rMhpYFT"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
